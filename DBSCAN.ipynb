{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0791b91",
   "metadata": {},
   "source": [
    "## Hi! \n",
    "### There i'll glad to introduce my implementation of DBSCAN alrorythm\n",
    "- to contact to me, check my git-bio\\\n",
    "Respectfully yours, \\\n",
    "    Yaugeniu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c96f3e4",
   "metadata": {},
   "source": [
    "Density-based spatial clustering of applications with noise (DBSCAN) is a data clustering algorithm proposed by Martin Ester, Hans-Peter Kriegel, Jörg Sander and Xiaowei Xu in 1996.[1] It is a density-based clustering non-parametric algorithm: given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away). DBSCAN is one of the most common clustering algorithms and also most cited in scientific literature.[2]\n",
    "\n",
    "In 2014, the algorithm was awarded the test of time award (an award given to algorithms which have received substantial attention in theory and practice) at the leading data mining conference, ACM SIGKDD.[3] As of July 2020, the follow-up paper \"DBSCAN Revisited, Revisited: Why and How You Should (Still) Use DBSCAN\"[4] appears in the list of the 8 most downloaded articles of the prestigious ACM Transactions on Database Systems (TODS) journal.[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caad3e6",
   "metadata": {},
   "source": [
    "Here some python3 code, go to section 2 to learn how 2 use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef051e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN myDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051298fc",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dadaa5",
   "metadata": {},
   "source": [
    "How to use:\\\n",
    "Parameters\n",
    "epsfloat, default=0.5\n",
    "The maximum distance between two samples for one to be considered as in the neighborhood of the other. This is not a maximum bound on the distances of points within a cluster. This is the most important DBSCAN parameter to choose appropriately for your data set and distance function.\n",
    "\n",
    "min_samplesint, default=5\n",
    "The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "\n",
    "metricstring, or callable, default=’euclidean’\n",
    "The metric to use when calculating distance between instances in a feature array. If metric is a string or callable, it must be one of the options allowed by sklearn.metrics.pairwise_distances for its metric parameter. If metric is “precomputed”, X is assumed to be a distance matrix and must be square. X may be a Glossary, in which case only “nonzero” elements may be considered neighbors for DBSCAN.\n",
    "\n",
    "New in version 0.17: metric precomputed to accept precomputed sparse matrix.\n",
    "\n",
    "metric_paramsdict, default=None\n",
    "Additional keyword arguments for the metric function.\n",
    "\n",
    "New in version 0.19.\n",
    "\n",
    "algorithm{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’\n",
    "The algorithm to be used by the NearestNeighbors module to compute pointwise distances and find nearest neighbors. See NearestNeighbors module documentation for details.\n",
    "\n",
    "leaf_sizeint, default=30\n",
    "Leaf size passed to BallTree or cKDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    "pfloat, default=None\n",
    "The power of the Minkowski metric to be used to calculate distance between points. If None, then p=2 (equivalent to the Euclidean distance).\n",
    "\n",
    "n_jobsint, default=None\n",
    "The number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.\n",
    "\n",
    "Attributes\n",
    "core_sample_indices_ndarray of shape (n_core_samples,)\n",
    "Indices of core samples.\n",
    "\n",
    "components_ndarray of shape (n_core_samples, n_features)\n",
    "Copy of each core sample found by training.\n",
    "\n",
    "labels_ndarray of shape (n_samples)\n",
    "Cluster labels for each point in the dataset given to fit(). Noisy samples are given the label -1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849b65f",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ddbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.cluster import DBSCAN\n",
    ">>> import numpy as np\n",
    ">>> X = np.array([[1, 2], [2, 2], [2, 3],\n",
    "...               [8, 7], [8, 8], [25, 80]])\n",
    ">>> clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
    ">>> clustering.labels_\n",
    "array([ 0,  0,  0,  1,  1, -1])\n",
    ">>> clustering\n",
    "DBSCAN(eps=3, min_samples=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
